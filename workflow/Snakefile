# Python standard library
from os.path import join
import os, sys, json

# Local imports
from scripts.common import (
    allocated,
    provided, 
    references,
    str_bool,
    depending
)

# Global workflow variables
configfile: 'config.json'                      # Generated from user input and config/*.json
workpath = config['project']['workpath']       # Pipeline's output directory
tmpdir   = config['options']['tmp_dir']        # Temporary directory
samples2barcodes = config['barcodes']          # Samples to demultiplex, `cat` together

# Find list of sample which 
# have mulitple barcodes, this 
# means they need to be merged  
barcoded_samples = [k for k in samples2barcodes if samples2barcodes[k]]
samples = list(config['barcodes'].keys())

# Determines if Conda or Singularity
# are used for software dependencies
use_singularity = True
use_conda =  str_bool(
     config['options']['use_conda']
) # default: False

# Use an extisting, named conda env
conda_env_name = config['options']['conda_env_name']                # default: ''
conda_yaml_or_named_env = join(workpath, config['conda']['mpox-seek']) # default: yaml for building
if conda_env_name:
    # Setup so user does not have
    # to provide the --use-conda 
    # option with --conda-env-name,
    # assumes if they provide the 
    # --conda-env-name option they
    # obviously want to use conda 
    # instead of singularity, allows
    # for backwards compatiability
    use_conda = True
    conda_yaml_or_named_env = conda_env_name    # Use an existing, named conda environment

# Use Singularity
if use_conda or conda_env_name:
    # Conda and Singularity 
    # are mutually exclusive 
    use_singularity = False


# Final output files of the pipeline,
# Rule DAG built from listed here 
rule all:
    input:
        # Merge samples with multiple barcodes,
        # @imported from `rule setup` in rules/trim.smk 
        expand(
            join(workpath, "{name}", "fastqs", "{name}.fastq.gz"), 
            name=samples
        ),
        # Adapter trimming step,
        # @imported from `rule porechop` in rules/trim.smk 
        expand(
            join(workpath, "{name}", "fastqs", "{name}.trimmed.fastq.gz"),
            name=samples
        ),
        # Align reads against monkeypox reference,
        # @imported from `rule minimap2` in rules/map.smk
        expand(
            join(workpath, "{name}", "bams", "{name}.sam"),
            name=samples
        ),
        # Create a consensus sequence from alignments
        # @imported from `rule consensus` in rules/map.smk
        expand(
            join(workpath, "{name}", "consensus", "{name}_consensus_seqid.fa"),
            name=samples
        ),
        # Create input file for MSA, concatenates the ref and 
        # each samples consequence sequence.
        # @imported from `rule concat` in rules/map.smk
        join(workpath, "project", "consensus.fa"),
        # Mutiple sequence alignment (MSA),
        # @imported from `rule mafft` in rules/map.smk
        join(workpath, "project", "msa.fa"),
        # Build a phylogentic tree from MSA,
        # @imported from `rule tree` in rules/tree.smk
        join(workpath, "project", "mpox_phylogeny.raxml.bestTree"),


# Import rules 
include: join("rules", "common.smk")
include: join("rules", "trim.smk")
include: join("rules", "map.smk")
include: join("rules", "tree.smk")
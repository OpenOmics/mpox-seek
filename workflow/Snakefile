# Python standard library
from os.path import join
import os, sys, json

# Local imports
from scripts.common import (
    allocated,
    provided, 
    references,
    str_bool,
    depending
)

# Global workflow variables
configfile: 'config.json'                      # Generated from user input and config/*.json
workpath = config['project']['workpath']       # Pipeline's output directory
tmpdir   = config['options']['tmp_dir']        # Temporary directory
samples2barcodes = config['barcodes']          # Samples to demultiplex, `cat` together
# Creates a unique sub directory
# within using the identifer with
# project level folder. This is to
# ensure files are not over-written
# between runs of the pipeline,
# needs to be added to paths in the
# project folder.
batch_id = config['options']['batch_id']                  # Batch Identifer, default: ''.
strains_fasta = config['options']['additional_strains']   # Additional strains fasta, default: "None"  
# Build phylogentic tree with
# additional mpox strains provided
# via --additional-strains option,
# If option is not provided, it will
# resolve to "None"
add_strains = False if strains_fasta == "None" else True
strains_fasta = strains_fasta if add_strains else ''

decompress_strains_fasta = False
if strains_fasta.endswith('.gz') or strains_fasta.endswith('.gzip'):
    decompress_strains_fasta = True 

# Maps branch support/confidence values
# to the best tree via bootstrapping data 
bootstrap_trees = str_bool(config['options']['bootstrap_trees'])

# Find list of sample which 
# have mulitple barcodes, this 
# means they need to be merged  
barcoded_samples = [k for k in samples2barcodes if samples2barcodes[k]]
samples = list(config['barcodes'].keys())

# Determines if Conda or Singularity
# are used for software dependencies
use_singularity = True
use_conda =  str_bool(
     config['options']['use_conda']
) # default: False

# Use an extisting, named conda env
conda_env_name = config['options']['conda_env_name']                # default: ''
conda_yaml_or_named_env = join(workpath, config['conda']['mpox-seek']) # default: yaml for building
if conda_env_name:
    # Setup so user does not have
    # to provide the --use-conda 
    # option with --conda-env-name,
    # assumes if they provide the 
    # --conda-env-name option they
    # obviously want to use conda 
    # instead of singularity, allows
    # for backwards compatiability
    use_conda = True
    conda_yaml_or_named_env = conda_env_name    # Use an existing, named conda environment

# Use Singularity
if use_conda or conda_env_name:
    # Conda and Singularity 
    # are mutually exclusive 
    use_singularity = False


# Final output files of the pipeline,
# Rule DAG built from listed here 
rule all:
    input:
        # Uncompress additional strains fasta file,
        # conditionally run if --additional-strains
        # option is provided and file is gzipped
        provided(
            [join(workpath, "project", "additional_strains.fa")],
            add_strains and decompress_strains_fasta
        ),
        # Merge samples with multiple barcodes,
        # @imported from `rule setup` in rules/trim.smk 
        expand(
            join(workpath, "{name}", "fastqs", "{name}.fastq.gz"), 
            name=samples
        ),
        # Adapter trimming step,
        # @imported from `rule porechop` in rules/trim.smk 
        expand(
            join(workpath, "{name}", "fastqs", "{name}.trimmed.fastq.gz"),
            name=samples
        ),
        # Align reads against monkeypox reference,
        # @imported from `rule minimap2` in rules/map.smk
        expand(
            join(workpath, "{name}", "bams", "{name}.sam"),
            name=samples
        ),
        # Create a consensus sequence from alignments
        # @imported from `rule consensus` in rules/map.smk
        expand(
            join(workpath, "{name}", "consensus", "{name}_consensus_seqid.fa"),
            name=samples
        ),
        # Create input file for MSA, concatenates the ref and 
        # each samples consequence sequence.
        # @imported from `rule concat` in rules/map.smk
        join(workpath, "project", batch_id, "consensus.fa"),
        # Mutiple sequence alignment (MSA),
        # @imported from `rule mafft` in rules/map.smk
        join(workpath, "project", batch_id, "msa.fa"),
        # Build a phylogentic tree from MSA,
        # @imported from `rule tree` in rules/tree.smk
        join(workpath, "project", batch_id, "mpox_phylogeny.raxml.bestTree"),


# Import rules 
include: join("rules", "common.smk")
include: join("rules", "trim.smk")
include: join("rules", "map.smk")
include: join("rules", "tree.smk")